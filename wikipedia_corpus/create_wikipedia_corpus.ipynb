{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリの読み込み\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 記事情報をデータフレームに格納する関数\n",
    "def text_corpus(article_file, file_name, hr_columns, max_hr):\n",
    "    \n",
    "    # データの定義\n",
    "    columns = [\"doc_id\", \"title\", \"table\"] + hr_columns.tolist() + [\"text\"]\n",
    "    article_list = []\n",
    "\n",
    "    for art_no in range(len(article_file)):\n",
    "\n",
    "        # 記事を抽出\n",
    "        n = len(article_file)\n",
    "        raw_article = article_file[art_no]\n",
    "\n",
    "        # タイトルを抽出\n",
    "        try:\n",
    "            doc_id0 = re.findall(\"<doc id=\\\"[0-9].+?\\\"\", raw_article)[0]\n",
    "            doc_id0 = int(re.findall(\"[0-9]+\", doc_id0)[0])\n",
    "            title0 = re.findall(\"title=\\\".*\\\"\", raw_article)[0]\n",
    "            title0 = re.sub(\"title=\\\"|\\\"\", \"\", title0)\n",
    "            # print(art_no, title0)\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        # header文を抽出\n",
    "        replace_str = \"(\\n.*\\n\\n|\\n<h[0-9]>|&lt.*?&gt;|href=\\\".+?\\\")\"\n",
    "        candidate_header0 = re.split(\"\\n<h[0-9]>.+?</h[0-9]>\", raw_article)\n",
    "        for i in range(len(candidate_header0)):\n",
    "            if len(re.findall(\"<doc id=.+>\", candidate_header0[i])) > 0:\n",
    "                header0 = candidate_header0[i]\n",
    "                break\n",
    "            else:\n",
    "                header0 = candidate_header0[0]\n",
    "        header0 = re.sub(\"<doc id=.+>{,1}\", \"\", header0)\n",
    "        header0 = re.sub(\"[ ]\", \"\", header0)\n",
    "        header0 = re.sub(replace_str, \"\", header0)\n",
    "\n",
    "        # 本文を抽出\n",
    "        replace_str1 = \"(&lt.*?&gt;|\\n)\"\n",
    "        replace_str2 = \"(<ul>|</ul>|<li>|</li>|<dl>|</dl>|<ls[0-9]></ls[0-9]>|</(?![a-zA-Z0-9]+>)|&lt;a[ ]?|a&gt;|href=\\\".+?\\\"|^(\\n)+)\"\n",
    "        text_candidate = re.split(\"<h[0-9]>\", raw_article)\n",
    "        text_table0 = []\n",
    "        text_list0 = []\n",
    "        for i in range(len(text_candidate)):\n",
    "            try:\n",
    "                table0 = re.findall(\"^.+?</h[0-9]>\", text_candidate[i])[0]\n",
    "                table0 = re.sub(replace_str1, \"\", table0)\n",
    "                text0 = re.sub(\"^.+?</h[0-9]>\", \"\", text_candidate[i])\n",
    "                text0 = re.sub(\"^\\n.+\\.\\n\", \"\", text0)\n",
    "                text0 = re.sub(\"^.+\\.\\n\", \"\", text0)\n",
    "                text0 = re.sub(\"&lt;main&gt;(.+?)&lt;/main&gt;\", \"<main>[[\\\\1]]</main>\", text0)\n",
    "                text0 = re.sub(\"&lt;also&gt;(.+?)&lt;/also&gt;\", \"<also>[[\\\\1]]</also> \", text0)\n",
    "                text0 = re.sub(\"&lt;main&gt;\", \"\", text0)\n",
    "                text0 = re.sub(\"&lt;also&gt;\", \"\", text0)\n",
    "                text0 = re.sub(replace_str2, \"\", text0)\n",
    "                text0 = re.sub(\"&gt;(.+?)&lt;/\", \"[[\\\\1]]\", text0)\n",
    "                if len(table0) > 0:\n",
    "                    text_table0.append(table0)\n",
    "                    text_list0.append(text0)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # テキストが無ければ飛ばす\n",
    "        if len(text_list0)==0:\n",
    "            continue\n",
    "\n",
    "        # tableの階層構造を定義\n",
    "        text_table0 = np.array(text_table0)\n",
    "        table0 = np.array([re.sub(\"</h[0-9]>\", \"\", text_table0[i]) for i in range(len(text_table0))])\n",
    "\n",
    "        table_hr = np.array([int(re.findall(\"</h[0-9]>\", text_table0[i])[0][3]) for i in range(len(text_table0))])\n",
    "        index1 = np.where(table_hr==2)[0].astype(\"int\")\n",
    "        index2 = np.arange(np.min(np.where(table_hr==2)[0]), len(text_table0)).astype(\"int\")\n",
    "        hr1 = np.repeat(\"\", len(text_table0)).astype(\"object\")\n",
    "        hr1[index2] = np.repeat(table0[index1], np.append(index1[1:], len(text_table0)) - index1)\n",
    "        hr1 = np.append(\"header\", hr1)\n",
    "        hr2 = np.full((len(text_table0)+1, max_hr), \"\").astype(\"object\")\n",
    "        for i in range(max_hr):\n",
    "            index2 = np.where(table_hr==i+3)[0].astype(\"int\")\n",
    "            if len(index2)==0:\n",
    "                continue\n",
    "            for j in range(len(index2)):\n",
    "                try:\n",
    "                    last_raw = np.min(np.hstack((index1[np.argmax(index1 >= index2[j])], index2[j+1]))) - 1\n",
    "                except:\n",
    "                    last_raw = index1[np.argmax(index1 >= index2[j])] - 1\n",
    "                raw = np.arange(index2[j], last_raw + 1)\n",
    "                hr2[raw+1, i] = str(table0[index2[j]])\n",
    "            index1 = np.unique(np.append(index1, index2))\n",
    "\n",
    "        # 新しい項目を定義\n",
    "        new_text_table0 = np.repeat(\"\", len(text_table0)).astype(\"object\")\n",
    "        for i in range(len(text_table0)):\n",
    "            tag = re.findall(\"</h[0-9]>\", text_table0[i])[0]\n",
    "            new_text_table0[i] = re.sub(\"/\", \"\", tag) + text_table0[i]\n",
    "\n",
    "        # データフレームに格納\n",
    "        titles = np.repeat(title0, len(text_table0) + 1).astype(\"U\")\n",
    "        doc_ids = ids = np.repeat(doc_id0, len(text_table0) + 1)\n",
    "        tables = np.hstack((np.append(\"header\", new_text_table0)[:, np.newaxis], hr1[:, np.newaxis], hr2)).astype(\"U\")\n",
    "        texts = np.append(header0, np.hstack((text_list0))).astype(\"U\")\n",
    "        article0 = pd.concat((pd.DataFrame(doc_ids), pd.DataFrame(titles), pd.DataFrame(tables), pd.DataFrame(texts)), axis=1)\n",
    "        article0.columns = columns\n",
    "\n",
    "        # リストに格納\n",
    "        article_list.append(article0)\n",
    "        \n",
    "    # データフレームを作成\n",
    "    articles = pd.concat((article_list), axis=0)\n",
    "    M = articles.shape[0]\n",
    "    articles.index = np.arange(M)\n",
    "    articles = pd.concat((pd.DataFrame({\"no\": np.arange(M), \"file\": np.repeat(file_name, M)}), articles), axis=1)\n",
    "    return articles\n",
    "\n",
    "\n",
    "# パラグラフ単位のコーパスを定義する関数\n",
    "def paragraph_corpus(articles, hr_columns, link_columns, max_link):\n",
    "\n",
    "    # カラムを定義\n",
    "    aux_columns = [\"file\", \"doc_id\", \"title\", \"table\"] + hr_columns.tolist()\n",
    "    ref_columns = [\"main\", \"also\"]\n",
    "    item_columns = [\"item\", \"item_detail\"]    \n",
    "    info_columns = ref_columns + item_columns + link_columns.tolist() + [\"itemization\", \"text\"]\n",
    "\n",
    "    # データの定義\n",
    "    ol_flag = 0\n",
    "    article0 = articles[aux_columns]\n",
    "    text0 = np.array(articles[\"text\"])\n",
    "    article_info_list = []\n",
    "    \n",
    "    \n",
    "    # textごとにパラグラフ単位でデータフレームに格納\n",
    "    for i in range(len(text0)):\n",
    "\n",
    "        # textをパラグラフに分割\n",
    "        split_text = text0[i].split(\"\\n\")\n",
    "\n",
    "        # 分割したtextが空白なら空白行を生成\n",
    "        if len(split_text)==0:\n",
    "            text_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            ol_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            main_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            also_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            item_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            detail_list0 = np.array([\"\"]).astype(\"object\")\n",
    "            link_list0 = np.repeat(\"\", max_list).astype(\"object\")\n",
    "            text_info = pd.DataFrame(np.hstack((main_list0[:, np.newaxis], also_list0[:, np.newaxis], item_list0[:, np.newaxis],\n",
    "                                                detail_list0[:, np.newaxis], link_list0, ol_list0[:, np.newaxis],\n",
    "                                                text_list0[:, np.newaxis])))\n",
    "            text_info.columns = info_columns\n",
    "\n",
    "        # リストの階層構造を定義\n",
    "        elif len(split_text) > 0:\n",
    "            text_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            ol_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            main_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            also_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            item_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            detail_list0 = np.repeat(\"\", len(split_text)).astype(\"object\")\n",
    "            link_list0 = np.full((len(split_text), max_link), \"\").astype(\"object\")\n",
    "            item_type= \"dt\"\n",
    "            item0 = \"\"\n",
    "\n",
    "            for j in range(len(split_text)):\n",
    "\n",
    "                if split_text[j]==\"<ol>\":\n",
    "                    ol_flag = 1\n",
    "                    ol_list0[j] = split_text[j]\n",
    "\n",
    "                elif ol_flag==1:\n",
    "                    if split_text[j]==\"</ol>\":\n",
    "                        ol_flag = 0\n",
    "                        ol_list0[j] = split_text[j]\n",
    "                    elif (len(split_text)-1)==j:\n",
    "                        ol_flag = 0\n",
    "                        text_list0[j] = split_text[j]\n",
    "                    else:\n",
    "                        ol_list0[j] = split_text[j]\n",
    "\n",
    "                elif split_text[j][:6]==\"<main>\":\n",
    "                    main_list0[j] = split_text[j]\n",
    "                    \n",
    "                elif split_text[j][:6]==\"<also>\":\n",
    "                    also_list0[j] = split_text[j]\n",
    "                    \n",
    "                elif split_text[j][:4]==\"<dt>\":\n",
    "                    item0 = split_text[j]\n",
    "                    item_type = \"dt\"\n",
    "                    try:\n",
    "                        if split_text[j+1][:4]!=\"<dd>\":\n",
    "                            item_list0[j] = item0\n",
    "                    except:\n",
    "                        item_list0[j] = item0\n",
    "                \n",
    "                elif split_text[j][:4]==\"<dd>\":\n",
    "                    detail0 = split_text[j]\n",
    "                    detail_list0[j] = detail0\n",
    "                    item_type = \"dd\"\n",
    "                    if (item_type==\"dt\") | (item_type==\"dd\"):\n",
    "                        item_list0[j] = item0\n",
    "\n",
    "                elif len(re.findall(\"<ls[0-9]>\", split_text[j])) > 0:\n",
    "                    col = int(split_text[j][3]) - 1\n",
    "                    link_list0[j, col] = split_text[j]\n",
    "\n",
    "                else:\n",
    "                    if len(split_text[j]) > 0:\n",
    "                        text_list0[j] = split_text[j] \n",
    "                        item_type = \"\"\n",
    "\n",
    "            # リストの階層構造を取得\n",
    "            new_link_list0 = np.full((len(split_text), max_link), \"\").astype(\"object\")\n",
    "            concat = np.hstack((text_list0[:, np.newaxis], item_list0[:, np.newaxis], detail_list0[:, np.newaxis], link_list0))\n",
    "            for j1 in range(max_link):\n",
    "                index1 = np.where(link_list0[:, j1])[0].astype(\"int\")\n",
    "                index2 = np.append(np.where(np.sum(concat[:, :j1+4]!=\"\", axis=1) > 0)[0], link_list0.shape[0]).astype(\"int\")\n",
    "                for j2 in range(len(index1)):\n",
    "                    raw = np.arange(index1[j2], np.min(index2[index2 > index1[j2]]))\n",
    "                    new_link_list0[raw, j1] = link_list0[index1[j2], j1]\n",
    "\n",
    "            # 情報を結合\n",
    "            text_info = pd.DataFrame(np.hstack((main_list0[:, np.newaxis], also_list0[:, np.newaxis], item_list0[:, np.newaxis],\n",
    "                                                detail_list0[:, np.newaxis], link_list0, ol_list0[:, np.newaxis],\n",
    "                                                text_list0[:, np.newaxis])))\n",
    "            text_info.columns = info_columns\n",
    "            \n",
    "            # 情報がないレコードを削除\n",
    "            ol_tag = [\"<ol>\", \"</ol>\"]\n",
    "            ol_itemization = np.array(text_info[\"itemization\"])\n",
    "            ol_text = np.array(text_info[\"text\"])\n",
    "            index_ol = (ol_itemization!=ol_tag[0]) & (ol_itemization!=ol_tag[1]) & (ol_text!=ol_tag[0]) & (ol_text!=ol_tag[1])\n",
    "            text_info = text_info.iloc[np.where(index_ol)[0]]\n",
    "            text_info = text_info.iloc[np.where(np.sum(text_info!=\"\", axis=1) > 0)[0]]            \n",
    "            text_info.index = np.arange(text_info.shape[0])\n",
    "            \n",
    "            \n",
    "        # データフレームを結合\n",
    "        rep_id = np.repeat(i, text_info.shape[0])\n",
    "        aux_info = article0.iloc[rep_id]\n",
    "        aux_info.index = np.arange(len(rep_id))\n",
    "        info = pd.concat((aux_info, text_info), axis=1)\n",
    "        article_info_list.append(info)\n",
    "\n",
    "    # データフレームを作成\n",
    "    article_info = pd.concat((article_info_list), axis=0)\n",
    "    N = article_info.shape[0]\n",
    "    article_info.index = np.arange(N)\n",
    "    article_info = pd.concat((pd.DataFrame({\"no\": np.arange(N)}), article_info), axis=1)\n",
    "    return article_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コーパスを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# データの読み込み\n",
    "# パスの定義\n",
    "path =\"E:/Statistics/data/wikipedia/\"\n",
    "folder = os.listdir(path + \"extract/\")\n",
    "filelist = [glob.glob(path + \"extract/\" + folder[i] + \"/*\") for i in range(len(folder))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AA\n",
      "------------テキスト単位のコーパスを作成------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "------------パラグラフ単位のコーパスを作成------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "AAのフォルダは存在します。\n",
      "AB\n",
      "------------テキスト単位のコーパスを作成------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "------------パラグラフ単位のコーパスを作成------------\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# コーパスを作成\n",
    "# カラムを定義\n",
    "max_hr = 6\n",
    "max_link = 9\n",
    "hr_columns = \"table\" + np.arange(max_hr+1).astype(\"U\").astype(\"object\")\n",
    "link_columns = \"link\" + np.arange(max_link).astype(\"U\").astype(\"object\")\n",
    "\n",
    "# フォルダごとにコーパスを作成\n",
    "# テキストファイルの読み込み\n",
    "for rp in range(len(filelist)): \n",
    "    print(folder[rp])\n",
    "    m = len(filelist[rp])\n",
    "    folder_name = folder[rp]\n",
    "    data = []\n",
    "    article_file = []\n",
    "    file_name = []\n",
    "\n",
    "    for j in range(m):\n",
    "        f = open(filelist[rp][j] , \"r\")\n",
    "        data.append(f.read())\n",
    "        f.close()\n",
    "\n",
    "        # 記事を分割\n",
    "        file_name.append(re.sub(\"\\\\\\\\\", \"/\", re.split(\"extract/\", filelist[rp][j])[1]))\n",
    "        article_file.append(data[j].split(\"\\n</doc>\\n\"))\n",
    "\n",
    "\n",
    "    # text単位のコーパスを作成\n",
    "    article_list = []\n",
    "    print(\"------------テキスト単位のコーパスを作成------------\")\n",
    "    for files in range(len(article_file)):\n",
    "        print(files)\n",
    "        article_list.append(text_corpus(article_file[files], file_name[files], hr_columns, max_hr))\n",
    "\n",
    "    # パラグラフ単位のコーパスを作成\n",
    "    article_info_list = []\n",
    "    print(\"------------パラグラフ単位のコーパスを作成------------\")\n",
    "    for files in range(len(article_list)):\n",
    "        print(files)\n",
    "        articles = article_list[files]\n",
    "        article_info_list.append(paragraph_corpus(articles, hr_columns, link_columns, max_link))\n",
    "\n",
    "    # リストを結合\n",
    "    articles = pd.concat((article_list), axis=0)\n",
    "    articles[\"no\"] = np.arange(articles.shape[0])\n",
    "    articles.index = np.arange(articles.shape[0])\n",
    "    article_info = pd.concat((article_info_list), axis=0)\n",
    "    article_info[\"no\"] = np.arange(article_info.shape[0])\n",
    "    article_info.index = np.arange(article_info.shape[0])\n",
    "    \n",
    "    # コーパスをデータフレームとして出力\n",
    "    # csvで出力\n",
    "    articles.to_csv(path + \"corpus/wikipedia_corpus_{}.csv\".format(folder_name), index=None)\n",
    "    article_info.to_csv(path + \"corpus/wikipedia_detail_corpus_{}.csv\".format(folder_name), index=None)\n",
    "\n",
    "    # ファイルを分割してexcel出力\n",
    "    split_size = 10\n",
    "    try:\n",
    "        os.mkdir(path + \"corpus/{}\".format(folder_name))\n",
    "    except:\n",
    "        print(\"{}のフォルダは存在します。\".format(folder_name))\n",
    "    split_index = np.array_split(np.arange(len(file_name)), split_size)\n",
    "\n",
    "    for i in range(len(split_index)):\n",
    "        split_index[i]\n",
    "        output_path = path + \"corpus/{}/\".format(folder_name)\n",
    "        target_file = np.array(file_name)[split_index[i]]\n",
    "        articles0 = articles.iloc[np.where(np.in1d(articles[\"file\"], target_file))[0]]\n",
    "        articles0.index = np.arange(articles0.shape[0])\n",
    "        article_info0 = article_info.iloc[np.where(np.in1d(article_info[\"file\"], target_file))[0]]\n",
    "        article_info0.index = np.arange(article_info0.shape[0])\n",
    "        articles0.to_excel(output_path + \"wikipedia_corpus_{}{}.xlsx\".format(folder_name, str(i)) , index=None)\n",
    "        article_info0.to_excel(output_path + \"wikipedia_detail_corpus_{}{}.xlsx\".format(folder_name, str(i)) , index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
